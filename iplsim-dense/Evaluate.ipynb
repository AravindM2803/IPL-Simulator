{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json\n",
    "from Utils.evaluation import EvaluationMetrics, ActualStats\n",
    "from Utils.helper import *\n",
    "from Utils.sample_squads import *\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 22,\n",
    "                            'font.weight': 'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History loss plot for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innings_number = 1\n",
    "with open(\"Models\\Inn1-HeavyDense-ep0to20\\history.pkl\", \"rb\") as fp:\n",
    "    history1 = pickle.load(fp)\n",
    "with open(\"Models\\Inn1-HeavyDense-ep20to50\\history.pkl\", \"rb\") as fp:\n",
    "    history2 = pickle.load(fp)\n",
    "history = {}\n",
    "for key in history1:\n",
    "    history[key] = history1[key] + history2[key]\n",
    "for key in sorted([i for i in history if i.split(\"_\")[0]!=\"val\"]):\n",
    "    epochs = len(history[key])\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(10, 7)\n",
    "    # plt.figure(dpi=300)\n",
    "    plt.plot([i for i in range(1, epochs+1)], history[key])\n",
    "    plt.plot([i for i in range(1, epochs+1)], history[\"val_\"+key])\n",
    "    plt.xlabel('epoch', fontweight='bold')\n",
    "    plt.ylabel(key, fontweight='bold')\n",
    "    plt.legend([\"Training\", \"Validation\"])\n",
    "    plt.title(f\"Innings {innings_number} - {key}\", fontweight='bold')\n",
    "    plt.savefig(f\"Images\\\\Training\\\\inn{innings_number}_{key}.jpeg\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innings_number = 2\n",
    "with open(\"Models\\Inn2-HeavyDenseRequired-ep0to20\\history.pkl\", \"rb\") as fp:\n",
    "    history1 = pickle.load(fp)\n",
    "with open(\"Models\\Inn2-HeavyDenseRequired-ep20to30\\history.pkl\", \"rb\") as fp:\n",
    "    history2 = pickle.load(fp)\n",
    "with open(\"Models\\Inn2-HeavyDenseRequired-ep30to50\\history.pkl\", \"rb\") as fp:\n",
    "    history3 = pickle.load(fp)\n",
    "history = {}\n",
    "for key in history1:\n",
    "    history[key] = history1[key] + history2[key] + history3[key]\n",
    "for key in sorted([i for i in history if i.split(\"_\")[0]!=\"val\"]):\n",
    "    epochs = len(history[key])\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(10, 7)\n",
    "    # plt.figure(dpi=300)\n",
    "    plt.plot([i for i in range(1, epochs+1)], history[key])\n",
    "    plt.plot([i for i in range(1, epochs+1)], history[\"val_\"+key])\n",
    "    plt.xlabel('epoch', fontweight='bold')\n",
    "    plt.ylabel(key, fontweight='bold')\n",
    "    plt.legend([\"Training\", \"Validation\"])\n",
    "    plt.title(f\"Innings {innings_number} - {key}\", fontweight='bold')\n",
    "    plt.savefig(f\"Images\\\\Training\\\\inn{innings_number}_{key}.jpeg\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inn1 = tf.keras.models.load_model('Models\\Inn1-HeavyDense-ep20to50\\cp-0029.h5')\n",
    "model_inn2 = tf.keras.models.load_model('Models\\Inn2-HeavyDenseRequired-ep30to50\\cp-0016.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EvaluationMetrics(model_inn1, model_inn2,\n",
    "                              # )\n",
    "                              \"Evaluation/tournament3_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_bs = set(BS_Cols)\n",
    "# for i in evaluator.teams:\n",
    "#     (batting, bowling), venue = i\n",
    "#     for name in batting[1:]:\n",
    "#         if \"Striker_\"+name not in set_bs:\n",
    "#             print(\"Striker_\"+name)\n",
    "#         if \"Non_Striker_\"+name not in set_bs:\n",
    "#             print(\"Non_Striker_\"+name)\n",
    "#         if \"Bowler_\"+name not in set_bs:\n",
    "#             print(\"Bowler_\"+name)\n",
    "#     for name in bowling[1:]:\n",
    "#         if \"Striker_\"+name not in set_bs:\n",
    "#             print(\"Striker_\"+name)\n",
    "#         if \"Non_Striker_\"+name not in set_bs:\n",
    "#             print(\"Non_Striker_\"+name)\n",
    "#         if \"Bowler_\"+name not in set_bs:\n",
    "#             print(\"Bowler_\"+name)\n",
    "#     if \"Venue_\"+venue not in set_bs:\n",
    "#         print(\"Venue_\"+venue)\n",
    "#     if \"Batting_Team_\"+batting[0] not in set_bs:\n",
    "#         print(\"Batting_Team_\"+batting[0])\n",
    "#     if \"Batting_Team_\"+bowling[0] not in set_bs:\n",
    "#         print(\"Batting_Team_\"+bowling[0])\n",
    "#     if \"Toss_\"+batting[0] not in set_bs:\n",
    "#         print(\"Toss_\"+batting[0])\n",
    "#     if \"Toss_\"+bowling[0] not in set_bs:\n",
    "#         print(\"Toss_\"+bowling[0])\n",
    "#     if \"Bowling_Team_\"+batting[0] not in set_bs:\n",
    "#         print(\"Bowling_Team_\"+batting[0])\n",
    "#     if \"Bowling_Team_\"+bowling[0] not in set_bs:\n",
    "#         print(\"Bowling_Team_\"+bowling[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_tournaments = 5\n",
    "# verbose = 0\n",
    "# for t in range(num_tournaments):\n",
    "#     print(f\"Tournament {t+1}/{num_tournaments}:\")\n",
    "#     evaluator.reinitialize_tournament()\n",
    "#     for _ in tqdm(range(56), ncols=80, disable=True if verbose!=0 else False):\n",
    "#         if verbose != 0:\n",
    "#             print(f\"\\n\\nMatch number: {evaluator.match_count+1}\")   \n",
    "#         evaluator.simulate_match(verbose)   \n",
    "#     evaluator.display_table()\n",
    "#     evaluator.save_object(\"Evaluation/tournament3_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actualstat = ActualStats(\"Evaluation/actual.pkl\")\n",
    "# actualstat = ActualStats()\n",
    "# actualstat.run_df(1, True)\n",
    "# actualstat.run_df(2, True)\n",
    "# actualstat.save_object(\"Evaluation/actual.pkl\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(actualstat.chasing_stat), len(actualstat.total_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Innings Target Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# stats.ttest_ind(evaluator.total_stat[::2], actualstat.total_stat, equal_var=False)\n",
    "stats.ks_2samp(evaluator.total_stat, actualstat.total_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(evaluator.total_stat), len(actualstat.total_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist([evaluator.total_stat, actualstat.total_stat], density=True, bins=10, label=[\"Our Simulation\", \"Actual Matches\"])\n",
    "plt.legend()\n",
    "plt.xlabel(\"First Innings Total\", fontweight='bold')\n",
    "plt.ylabel(\"Relative Frequency\", fontweight='bold')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 8)\n",
    "plt.savefig(\"Images\\\\Evaluation\\\\inn1_total_histogram.jpeg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import math\n",
    "mean_sim = statistics.mean(evaluator.total_stat)\n",
    "variance_sim = statistics.variance(evaluator.total_stat)\n",
    "stdev_sim = statistics.stdev(evaluator.total_stat)\n",
    "mean_actual = statistics.mean(actualstat.total_stat)\n",
    "variance_actual = statistics.variance(actualstat.total_stat)\n",
    "stdev_actual = statistics.stdev(actualstat.total_stat)\n",
    "z = abs(mean_actual - mean_sim)/(math.sqrt(variance_actual+variance_sim))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sim, mean_actual, stdev_sim, stdev_actual, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Innings Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_chasing_stat = actualstat.chasing_stat\n",
    "# evaluator_chasing_stat = evaluator.chasing_stat\n",
    "# actual_chasing_stat\n",
    "evaluator_chasing_stat = []\n",
    "for inn1, inn2 in evaluator.innings_obj_list:\n",
    "    row_dic = {}\n",
    "    row_dic[\"Final_Score\"] = [inn2.Runs, inn2.Wickets]\n",
    "    row_dic[\"First_Innings_Score\"] = inn1.Runs\n",
    "    row_dic[\"Overs\"] = [inn2.Overs - 1, inn2.Balls - 1]\n",
    "    row_dic[\"Chasing_Team\"] = inn2.Batting_Team\n",
    "    row_dic[\"Defending_Team\"] = inn2.Bowling_Team\n",
    "    final_score = inn2.Runs\n",
    "    first_innings_score = inn1.Runs\n",
    "    if final_score > first_innings_score:\n",
    "            outcome = 1\n",
    "    elif final_score == first_innings_score:\n",
    "        outcome = 0\n",
    "    elif final_score < first_innings_score:\n",
    "        outcome = -1\n",
    "    else:\n",
    "        assert False, \"Wrong if conditions\"\n",
    "    row_dic[\"Outcome\"] = outcome\n",
    "    evaluator_chasing_stat.append(row_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_chasing_outcome = [i[\"Outcome\"] for i in actual_chasing_stat]\n",
    "evaluator_chasing_outcome = [i[\"Outcome\"] for i in evaluator_chasing_stat]\n",
    "pie_lis = []\n",
    "labels = [\"Chasing Team Lost\", \"Tie\", \"Chasing Team Won\"]\n",
    "for outcome_lis in [evaluator_chasing_outcome, actual_chasing_outcome]:\n",
    "    res_dist = {}\n",
    "    for res in (outcome_lis):\n",
    "        if res in res_dist:\n",
    "            res_dist[res] += 1\n",
    "        else:\n",
    "            res_dist[res] = 1\n",
    "    pie_lis.append([res_dist[i] for i in sorted(res_dist)])\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 10)\n",
    "plt.pie(pie_lis[0], labels=labels, autopct=\"%.2f\")\n",
    "plt.legend(title = \"Our Simulation\")\n",
    "plt.savefig(\"Images\\\\Evaluation\\\\inn2_chasing_dist_simulation.jpeg\", dpi=300)\n",
    "plt.show()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 10)\n",
    "plt.pie(pie_lis[1], labels=labels, autopct=\"%.2f\")\n",
    "plt.legend(title = \"Actual Matches\", loc=\"lower right\")\n",
    "plt.savefig(\"Images\\\\Evaluation\\\\inn2_chasing_dist_actual.jpeg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 50\n",
    "thresh = 1\n",
    "def my_autopct(pct):\n",
    "    return ('%.2f' % pct) if pct > thresh else ''\n",
    "for inn1_start, inn1_end in [[i+1, i+step] for i in range(50, 250, step)]:\n",
    "    actual_chasing_outcome = [i[\"Outcome\"] for i in actual_chasing_stat \n",
    "                            if (inn1_start <= i[\"First_Innings_Score\"] <= inn1_end)]\n",
    "    evaluator_chasing_outcome = [i[\"Outcome\"] for i in evaluator_chasing_stat\n",
    "                                if (inn1_start <= i[\"First_Innings_Score\"] <= inn1_end)]\n",
    "    pie_lis = []\n",
    "    labels = [\"Chasing Team Lost\", \"Tie\", \"Chasing Team Won\"]\n",
    "    for outcome_lis in [evaluator_chasing_outcome, actual_chasing_outcome]:\n",
    "        res_dist = { -1: 0, 0: 0, 1: 0}\n",
    "        for res in (outcome_lis):\n",
    "            if res in res_dist:\n",
    "                res_dist[res] += 1\n",
    "            else:\n",
    "                res_dist[res] = 1\n",
    "        pie_lis.append([res_dist[i] for i in sorted(res_dist)])\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(14, 14)\n",
    "    labels_new = [labels[i] if pie_lis[0][i]/sum(pie_lis[0])*100 >= thresh else ''\n",
    "          for i in range(len(labels))]\n",
    "\n",
    "    legend_loc = \"upper right\"\n",
    "    if inn1_end == 150:\n",
    "        legend_loc = \"lower right\"\n",
    "    \n",
    "    plt.pie(pie_lis[0], labels=[\"\"]*len(labels_new), autopct=my_autopct)\n",
    "    plt.legend(labels=labels, title=\"Match Outcome\", loc=legend_loc)\n",
    "    plt.title(f\"Our Simulation target \\nfrom {inn1_start} to {inn1_end}\", fontweight='bold')\n",
    "    plt.savefig(f\"Images\\\\Evaluation\\\\inn2_chasing_dist_{inn1_start}to{inn1_end}_simulation.jpeg\", dpi=300)\n",
    "    plt.show()\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(14, 14)\n",
    "    labels_new = [labels[i] if pie_lis[1][i]/sum(pie_lis[1])*100 >= thresh else ''\n",
    "          for i in range(len(labels))]\n",
    "    plt.pie(pie_lis[1], labels=[\"\"]*len(labels_new), autopct=my_autopct)\n",
    "    plt.legend(labels=labels, title=f\"Match Outcome\", loc=legend_loc)\n",
    "    plt.title(f\"Actual Matches  target \\nfrom {inn1_start} to {inn1_end}\", fontweight='bold')\n",
    "    plt.savefig(f\"Images\\\\Evaluation\\\\inn2_chasing_dist_{inn1_start}to{inn1_end}_actual.jpeg\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = set(evaluator.season_table.keys())\n",
    "labels = [\"Loose\", \"Tie\", \"Win\"]\n",
    "team_outcome_dic = [{team: [0, 0, 0] for team in teams}, {team: [0, 0, 0] for team in teams}]\n",
    "for ind, val in enumerate([evaluator_chasing_stat, actual_chasing_stat]):\n",
    "    for match_stat in val:\n",
    "        if match_stat[\"Chasing_Team\"] not in teams or match_stat[\"Defending_Team\"] not in teams:\n",
    "            continue\n",
    "        if outcome == -1:\n",
    "            team_outcome_dic[ind][match_stat[\"Chasing_Team\"]][0] += 1\n",
    "            team_outcome_dic[ind][match_stat[\"Defending_Team\"]][2] += 1\n",
    "        if outcome == 0:\n",
    "            team_outcome_dic[ind][match_stat[\"Chasing_Team\"]][1] += 1\n",
    "            team_outcome_dic[ind][match_stat[\"Defending_Team\"]][1] += 1\n",
    "        if outcome == 1:\n",
    "            team_outcome_dic[ind][match_stat[\"Chasing_Team\"]][2] += 1\n",
    "            team_outcome_dic[ind][match_stat[\"Defending_Team\"]][1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for team in teams:\n",
    "#     fig = plt.gcf()\n",
    "#     fig.set_size_inches(8, 8)\n",
    "#     plt.pie(team_outcome_dic[0][team], labels=labels, autopct=\"%.2f\")\n",
    "#     plt.legend(title = f\"Our Simulation: {team}\")\n",
    "#     plt.show()\n",
    "#     fig = plt.gcf()\n",
    "#     fig.set_size_inches(8, 8)\n",
    "#     plt.pie(team_outcome_dic[1][team], labels=labels, autopct=\"%.2f\")\n",
    "#     plt.legend(title = f\"Actual Match: {team}\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = ((1, 6), (7, 10), (11, 15), (16, 20))\n",
    "# actualstat = ActualStats(intervals=intervals)\n",
    "# actualstat.run_df(1, True)\n",
    "# actualstat.run_df(2, True)\n",
    "over_to_interval = {}\n",
    "for interval in intervals:\n",
    "    for i in range(interval[0], interval[1]+1):\n",
    "        over_to_interval[i] = interval\n",
    "new_progress_stat = {\"runs\": {i:[] for i in intervals},\n",
    "                     \"wickets\": {i:[] for i in intervals},}\n",
    "for inn1, inn2 in (evaluator.innings_obj_list):\n",
    "    for inn in [inn1, inn2]:\n",
    "        innings_progress = {\"runs\": {i:0 for i in intervals},\n",
    "                            \"wickets\": {i:0 for i in intervals},}\n",
    "        for ind, over_summary in enumerate(inn.Overs_Summary):\n",
    "            o = ind+1\n",
    "            innings_progress[\"runs\"][over_to_interval[o]] += over_summary[0]\n",
    "            innings_progress[\"wickets\"][over_to_interval[o]] += over_summary[1]\n",
    "        for key in innings_progress:\n",
    "            for interval in intervals:\n",
    "                if o < interval[1]:\n",
    "                    continue\n",
    "                new_progress_stat[key][interval].append(innings_progress[key][interval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "bins = {\"runs\": 15, \"wickets\": 20}\n",
    "scored_taken = {\"runs\": \"scored\", \"wickets\": \"taken\"}\n",
    "for key in [\"runs\", \"wickets\"]:\n",
    "    for interval in (intervals):\n",
    "        plt.hist([new_progress_stat[key][interval], actualstat.new_progression_stat[key][interval]],\n",
    "                 density=True, bins=bins[key], label=[\"Our Simulation\", \"Actual Matches\"])\n",
    "        plt.legend()\n",
    "        plt.xlabel(f\"{key.title()} {scored_taken[key]} in {interval[0]}-{interval[1]}\", fontweight='bold')\n",
    "        plt.ylabel(\"Relative Frequency\", fontweight='bold')\n",
    "        fig = plt.gcf()\n",
    "        fig.subplots_adjust(bottom=0.15)\n",
    "        fig.subplots_adjust(left=0.15)\n",
    "        fig.set_size_inches(10, 5)\n",
    "        plt.savefig(f\"Images\\\\Evaluation\\\\progress_eval_{key}_{interval[0]}to{interval[1]}_histogram.jpeg\", dpi=300)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(actualstat.new_progression_stat[\"runs\"][intervals[0]]),len(actualstat.new_progression_stat[\"runs\"][intervals[1]]),len(actualstat.new_progression_stat[\"runs\"][intervals[2]]),len(actualstat.new_progression_stat[\"runs\"][intervals[3]]))\n",
    "print(len(new_progress_stat[\"runs\"][intervals[0]]),len(new_progress_stat[\"runs\"][intervals[1]]),len(new_progress_stat[\"runs\"][intervals[2]]),len(new_progress_stat[\"runs\"][intervals[3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# for key in [\"runs\", \"wickets\"]:\n",
    "#     for i in range(4):\n",
    "#         plt.hist([[k for k in evaluator.progression_stat[key][i] if k!=0], [k for k in actualstat.progression_stat[key][i] if k!=0]],\n",
    "#                  density=True, bins=10, label=[\"Our Simulation\", \"Actual Matches\"])\n",
    "#         plt.legend()\n",
    "#         plt.xlabel(f\"{key.title()} scored in {i*5+1}-{i*5+5}\")\n",
    "#         plt.ylabel(\"Relative Frequency\")\n",
    "#         fig = plt.gcf()\n",
    "#         fig.set_size_inches(8, 4)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batsmen Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batsmen_result_dic = {}\n",
    "bat_stat = evaluator.batsmen_stat\n",
    "for batsman in bat_stat:\n",
    "    tot_runs = 0\n",
    "    tot_balls = 0\n",
    "    num_4 = 0\n",
    "    num_6 = 0\n",
    "    num_inn = 0\n",
    "    num_out = 0\n",
    "    hs = [0, \"\"]\n",
    "    dismissal_type = []\n",
    "    dismissed_by = []\n",
    "    for i in bat_stat[batsman]:\n",
    "        num_inn += 1\n",
    "        tot_runs += i[\"Runs\"]\n",
    "        if i[\"Runs\"] > hs[0] or (i[\"Runs\"] == hs[0] and hs[1] == \"\"):\n",
    "            hs[0] = i[\"Runs\"]\n",
    "            if i[\"Dismissal Type\"] != \"Not Out\":\n",
    "                hs[1] = \"*\"\n",
    "        tot_balls += i[\"Balls Faced\"]\n",
    "        num_4 += i[\"Fours\"]\n",
    "        num_6 += i[\"Sixes\"]\n",
    "        if i[\"Dismissal Type\"] != \"Not Out\":\n",
    "            num_out += 1\n",
    "        dismissal_type.append(i[\"Dismissal Type\"])\n",
    "        dismissed_by.append(i[\"Dismissed By\"])\n",
    "    batsmen_result_dic[batsman] = {\n",
    "        \"Innings\": num_inn,\n",
    "        \"Runs\": tot_runs,\n",
    "        \"Balls\": tot_balls,\n",
    "        \"Fours\": num_4,\n",
    "        \"Sixes\": num_6,\n",
    "        \"High Score\": \"\".join([str(i) for i in hs]),\n",
    "        \"Average\": tot_runs/num_out if num_out!=0 else tot_runs,\n",
    "        \"Strike Rate\": tot_runs/tot_balls*100 if tot_balls!=0 else 0,\n",
    "        \"Boundry Percent\": (6*num_6+4*num_4)/tot_runs*100 if tot_runs!=0 else 0,\n",
    "        }\n",
    "batsmen_stat_df = pd.DataFrame.from_dict(batsmen_result_dic, orient='index')\n",
    "save_df = batsmen_stat_df.sort_values(by=[\"Runs\", \"Balls\"], ascending=False)\n",
    "save_df.to_csv(\"Evaluation/Evaluate_Batsmen.csv\")\n",
    "save_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bowler Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowler_result_dic = {}\n",
    "bowler_stat = evaluator.bowler_stat\n",
    "for bowler in bowler_stat:\n",
    "    tot_runs = 0\n",
    "    tot_balls = 0\n",
    "    tot_wickets = 0\n",
    "    for i in bowler_stat[bowler]:\n",
    "        tot_runs += i[\"Runs Conceded\"]\n",
    "        tot_balls += i[\"Balls\"]\n",
    "        tot_wickets += i[\"Wickets Taken\"]\n",
    "    bowler_result_dic[bowler] = {\n",
    "        \"Runs Conceded\": tot_runs,\n",
    "        \"Overs\": f\"{tot_balls//6}.{tot_balls%6}\",\n",
    "        \"Wickets\": tot_wickets,\n",
    "        \"Economy\": tot_runs/tot_balls*6 if tot_balls != 0 else 0,\n",
    "        }\n",
    "bowler_stat_df = pd.DataFrame.from_dict(bowler_result_dic, orient='index')\n",
    "save_df = bowler_stat_df.sort_values(by=[\"Wickets\", \"Economy\"], ascending=[False, True])\n",
    "save_df.to_csv(\"Evaluation/Evaluate_Bowler.csv\")\n",
    "save_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Players Matchwise Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_batsmen_df = pd.read_csv(\"Evaluation/Actual_Batsmen.csv\")\n",
    "evaluate_batsmen_df = pd.read_csv(\"Evaluation/Evaluate_Batsmen.csv\")\n",
    "actual_bowler_df = pd.read_csv(\"Evaluation/Actual_Bowler.csv\")\n",
    "evaluate_bowler_df = pd.read_csv(\"Evaluation/Evaluate_Bowler.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for player in list(actual_batsmen_df[\"Unnamed: 0\"])[:5]: \n",
    "    if player not in evaluator.batsmen_stat:\n",
    "        continue\n",
    "    player_actual = [i[\"Runs\"] for i in actualstat.batsmen_stat[player]]\n",
    "    player_evaluator = [i[\"Runs\"] for i in evaluator.batsmen_stat[player]]\n",
    "    plt.hist([player_evaluator, player_actual], \n",
    "            density=True, bins=10,\n",
    "            label=[\"Our Simulation\", \"Actual Matches\"])\n",
    "    plt.legend()\n",
    "    plt.xlabel(f\"{player} runs in a match\", fontweight='bold')\n",
    "    plt.ylabel(\"Relative Frequency\", fontweight='bold')\n",
    "    fig = plt.gcf()\n",
    "    fig.subplots_adjust(bottom=0.15)\n",
    "    fig.subplots_adjust(left=0.15)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    plt.savefig(f\"Images\\\\Evaluation\\\\runs_histogram_{'_'.join(player.split())}.jpeg\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for player in list(actual_bowler_df[\"Unnamed: 0\"])[:6]: \n",
    "    if player not in evaluator.bowler_stat:\n",
    "        continue\n",
    "    player_actual = [i[\"Wickets Taken\"] for i in actualstat.bowler_stat[player]]\n",
    "    player_evaluator = [i[\"Wickets Taken\"] for i in evaluator.bowler_stat[player]]\n",
    "    plt.hist([player_evaluator, player_actual], \n",
    "            density=True, bins=10,\n",
    "            label=[\"Our Simulation\", \"Actual Matches\"])\n",
    "    plt.legend()\n",
    "    plt.xlabel(f\"{player} wickets in a match\", fontweight='bold')\n",
    "    plt.ylabel(\"Relative Frequency\", fontweight='bold')\n",
    "    fig = plt.gcf()\n",
    "    fig.subplots_adjust(bottom=0.15)\n",
    "    fig.subplots_adjust(left=0.15)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    plt.savefig(f\"Images\\\\Evaluation\\\\wickets_histogram_{'_'.join(player.split())}.jpeg\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pronisi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "704e6597f63c23efc5b17f2fdd3ea65850a2c069267af86ca08a696d1a56cda7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
